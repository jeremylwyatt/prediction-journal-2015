\section{The Importance of Prediction for Manipulation}
\label{sec:motivation}
There is a large body of evidence that the human motor system uses predictive (or forward) models. These are models of the effects that motor actions have on sensory state \citep{flanagan03,flanagan06,mehta02,witney00,johansson92}. The predictions are used for a variety of purposes, including feedforward control, coordination of motor systems, action planning, and monitoring of action plan execution. Although these forward models are used in many motor systems, neuroscientists have highlighted their particular importance for human manipulation abilities:

\begin{quotation} the remarkable manipulative skill of the human hand is not the result of rapid sensorimotor processes, nor of fast or powerful effector mechanisms. Rather the secret lies in the way manual tasks are  organised and controlled by the nervous system. At the heart of this organization is prediction. Successful manipulation requires the ability both to predict the motor commands required to grasp, lift and move objects, and to predict the sensory events that arise as a consequence of these commands. --- \citep{flanagan06}
\end{quotation}

There is also evidence that predicting contact events is an essential part of the prediction process for human manipulation skills \citep{flanagan06}. This is because contact events during manipulation are used to assess intrinsic parameters of the manipulated object (friction, weight) as well as to monitor progress during the manipulative task. Each contact event also indicates the gain (loss) of a constraint on object motion. The motion behaviour of the object changes non-smoothly with such contacts. This means that to manipulate skillfully humans are likely to recruit and de-recruit  forward models of object behaviour as contacts change.  Finally there is evidence that prediction is learned before control \citep{flanagan03}, suggesting that it is necessary to learn to predict object behaviour before learning to control it.

Predictive models also have great utility in robot manipulation. One approach is to build a model informed by theories of mechanics \citep{mason_manipulator_1982,lynch_mechanics_1992,lynchmason96,peshkin_motion_1988,cappelleri_designing_2006,mason_mechanics_2001,flickinger2015},  to make predictions of robot and object motion under contact. Various analytic models exist, some making the quasi-static assumption, and others modelling dynamics. These approaches are appealing in that proofs concerning the qualitative object motion can be obtained, particularly under quasi-static conditions \citep{mason1985robot,peshkin_motion_1988}. This led to methods for push planning that have some guarantees, such as completeness and optimality \citep{lynchmason96}. To make precise, rather than qualitative predictions, these analytic models require explicit representation of intrinsic parameters of the object and its surroundings, such as friction, mass, mass distribution and coefficients of restitution. These are not trivial to estimate. Even if these parameters are correctly estimated, approximations in the predictive model can render predictions inaccurate. These two facts make the production of precise, metric predictions still beyond our reach for most cases. Despite the challenges, such a mechanics informed approach has promise, and much useful work on push planning uses either purely kinematic models \citep{stillman08ijrr}, quasi static models \citep{Dogar_2010,lynchmason96} or rigid body dynamics engines \cite{zitoetal-iros12,Cosgun2011}. 
\def\stackalignment{l}
\begin{figure*}[t]
\centerline{\stackinset{l}{0.47in}{t}{0.16in}{(a)}{\stackinset{l}{2.0in}{t}{0.16in}{(b)}{\stackinset{l}{4.3in}{t}{0.16in}{(c)}}}\includegraphics[width=0.85\textwidth]{three-prediction-problems}}
\caption{Three types of prediction problem. A robot finger is shown in blue, objects in black, and motions of the finger as dashed lines with arrows. Top row: training actions. Bottom row: an example test action. Each column represents a different problem. Sub-figure (a): Problem 1 - Action Interpolation. Subfigure (b): Problem 2 - Transfer to novel actions. Sub-figure (c): Problem 3 - Transfer to novel shapes. \label{fig:three-prediction-problems}}
\end{figure*}
Whatever the benefits and difficulties of using models informed by mechanics, since there is evidence that in humans the forward models are learned, it is an interesting question to ask whether machine learning can be used to acquire forward models of object behaviour. The principle has been understood for a long time \citep{JordanJacobs90,JordanRumelhart92}. There has also been application to robotics. There has, for example, been work on learning the observation effects, and the non-linear dynamics, of manipulators moving in free space \citep{Ting06,Boots14,dearden2005learning}. There has also been work on learning the qualitative motions of objects under pushing actions, and of the variables that influence the motion type \citep{montesano08,moldovan12,hermans11,fitzpatrick_learning_2003,ridge2010self,kroemer2014}. Finally there have recently been learned models of the metric motions of stable objects on a plane \citep{mericli2014}, of the motions of objects manipulated by tools \citep{Stoytchev_affordances_2008}, and of stable pushing locations \citep{hermans13}. These learning approaches all essentially learn the correlations of actions and observed effects. This is broadly the approach we take here, but we attempt to extend these statistical approaches to learning the full rigid body motions of objects in 3D space. A pushed object may, twist, slide, topple, and/or contact another surface. Although there are many papers on learning forward models, none of the extant work in robotics concerns the general case of making precise (metric) predictions of object motion, when the object can have changing contacts with the robot and environment. How can such contact constraints be incorporated into the learned model? Moreover, how can learning possibly hope to achieve the major benefit of physics simulation: generality? 

While we will not produce final solutions to these problems in this paper, we will make steps in the right direction. Specifically we will show how to learn metrically accurate models for specific objects, and how to learn models that have some capacity to be transferred to other, novel, objects and actions. To achieve this we propose a modular architecture inspired by models from computational neuroscience. We combine the insights of this architecture with frameworks and methods for supervised machine learning. 
