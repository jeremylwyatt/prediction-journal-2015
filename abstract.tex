Human manipulation relies on an ability to predict object behaviour during manipulation. Humans learn predictors which can be tuned for specific objects. This paper presents a prediction scheme inspired by models from computational neuroscience. First, we formulate the prediction problem for the quasi-static case, and in two different machine learning frameworks: i) regression and ii) density estimation. The prediction architecture is modular: many simple object and context specific predictors are learned. We describe the kinds of contact information necessary to predict, and show that object specific predictors typically outperform a tuned rigid body simulator. We then extend the density estimation approach to transfer learning, using a factored representation of contacts. This formulation permits transfer of learning to objects of novel shape, and to novel actions. We show empirically that transfer learning can match the performance of physics simulation, but only when using a factored model, and information on all contact relations in which the object participates.